<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Index - Beyond Gaze Catalogue</title>
  <link rel="stylesheet" href="index.css">
 <link rel="icon" href="/favicon.ico?v=2">
  <link href="https://fonts.googleapis.com/css2?family=EB+Garamond&display=swap" rel="stylesheet">
  <style>
.tts-controls {
    display: flex;
    flex-direction: column; /* stack buttons vertically */
    align-items: flex-start; /* align left */
    gap: 1px; /* small space between buttons */
    margin: 0; /* remove any default margin */
}

.tts-controls button {
    background: none; /* remove button background */
    border: none;     /* remove button border */
    padding: 0;       /* remove padding */
    cursor: pointer;
    font-family: 'Arial Black', sans-serif; /* your chosen font */
    color: red;       /* red text */
    font-size: 14px;
  font-weight: bold;  
}

.tts-controls button:hover {
    color: black;       /* red text */
}
</style>
    <style>
.glide-menu {
  margin-top: 8px;
}

.main-glide-btn {
  background: none;
  border: none;
  font-family: 'Arial Black', sans-serif;
  font-size: 14px;
  cursor: pointer;
  padding: 4px 0;
  text-align: left;
}

.main-glide-btn:hover {
  color: red;
}

.glide-options {
  display: flex;
  flex-direction: column;
  overflow: hidden;
  max-height: 0;
  opacity: 0;
  transition: max-height 0.5s ease, opacity 0.5s ease;
}

.glide-menu.active .glide-options {
  max-height: 500px; /* increase so all links fit */
  opacity: 1;
}

.glide-options a {
  text-decoration: none;
  font-size: 14px;
  color: red;
  margin: 2px 0;
  padding-left: 12px;
}
.glide-options a:hover {
  color: red;
}
    /* index1.css styles for main content only */
    .main-content {
      font-family: 'EB Garamond', serif;
      font-weight: normal !important;
      color: black !important;
      max-width: 650px;
      font-weight: 400;  
      font-size: 15px !important;
      line-height: 1.25 !important;
      margin-left: 40px !important;
    }

    .main-content .header {
      margin-bottom: 30px;
    }

    .main-content .strategies-main-title,
    .main-content .main-title {
      font-weight: bold !important;
      font-size: 15px !important;
      margin-top: 15px; /* adjust as needed */
      margin-bottom: 5px;
    }

    .main-content .strategies-attribution,
    .main-content .attribution {
      font-size: 12px !important;
      font-style: italic !important;
    }

    .main-content .strategy-section,
    .main-content .strategy {
      margin-bottom: 40px !important;
    }

    .main-content .strategy-section-title,
    .main-content .strategy-title {
      font-weight: bold !important;
      font-size: 15px !important;
      margin-bottom: 10px !important;
      
    }
    .main-content .strategy-title em {
  font-weight: normal !important;
}

    .main-content .section-label {
      font-weight: bold !important;
    }

    .main-content .strategy p,
    .main-content p {
      margin-bottom: 12px !important;
    }

    .main-content .strategy-references,
    .main-content .references {
      font-size: 12px !important;
      margin-top: 15px !important;
      line-height: 1.3 !important;
      padding-left: 0px !important;
      text-indent: 0px !important;
      font-family: "Times New Roman", Georgia, serif !important;
    }

    .main-content .strategy-references a,
    .main-content .references a {
      color: red !important;
      text-decoration: underline !important;
      font-weight: normal !important;
    font-family: "Times New Roman", Georgia, serif !important;
    }
  </style>
     <!-- Meta Description (invisible to visitors) -->
  <meta name="description" content="Beyond Gaze Catalogue explores touch as an artistic and pedagogical medium, developing a touch-led dramatic inquiry framework to enhance artistic collaboration, sense-making, and inclusive education among children with diverse abilities.">

 <!-- Structured Data for Google and Google Scholar (invisible) -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Touch-led Dramatic Inquiry: Beyond Gaze Research Catalogue",
    "author": {
      "@type": "Person",
      "name": "Can Boyan",
      "affiliation": [
        {
          "@type": "Organization",
          "name": "Royal Conservatoire of Antwerp"
        },
        {
          "@type": "Organization",
          "name": "University of Antwerp ARIA"
        }
      ]
    },
    "datePublished": "2025-09-11",
    "publisher": {
      "@type": "Organization",
      "name": "Beyond Gaze Catalogue"
    },
    "description": "This research investigates touch as an artistic and pedagogical medium, and proposes a touch-led dramatic inquiry framework for inclusive and full-bodied educational experiences among children with and without sensory impairments.",
    "url": "https://www.beyondgaze.work/info.html"
  }
  </script>

  <!-- Optional: Robots Meta Tag (invisible) -->
  <meta name="robots" content="index, follow">

</head>
<body class="catalogue-page">
  <div class="container">
    <aside class="sidebar">
      <h1><a href="index.html">BEYOND GAZE CATALOGUE</a></h1>
      <nav>
        <div class="menu-group">
          <ul>
            <li><a href="archive.html">Archive</a></li>
            <li><a href="index1.html">Index</a></li>
          </ul>
        </div>
       <div class="menu-group">

<div class="glide-menu">
<a href="#" class="main-glide-btn">Practice</a>
  
  <div class="glide-options">
    <a href="SpecialEd.html">Special Education</a>
    <a href="TactileScores.html">Tactile Scores</a>
  </div>
</div>
</div>
        <div class="menu-info">
          <ul>
            <li><a href="info.html">Info</a></li>
          </ul>
        </div>
      </nav>
      <div class="info">
        <p><strong>Last edited Thu Feb 12<br>16:00:24 2025<br>UTC +2</strong></p>
        <p><strong><a href="contact.html">Contact</a> - <a href="license.html">License</a></strong></p>
      </div>
        <div class="tts-controls">
  <button id="readTextBtn"> Read Page</button>
  <button id="stopTextBtn"> Stop</button>
</div>
    </aside>

    <div class="main-content">
      <div class="header">
        <div class="main-title">Touch-led Artistic Strategies: Index</div>
<p style="font-size: 13px; margin-top: 2px; margin-bottom: 0;">
  Boyan, C. (2025). Beyond Gaze Research Catalogue. 
  <a href="https://doi.org/10.5281/zenodo.17316698" style="color: red;">
    https://doi.org/10.5281/zenodo.17316698
  </a>
</p>
      </div>


      <!-- Strategy 1 -->
      <div class="strategy" data-node="1">
        <div class="strategy-title">Tactile Storying <em>(Sequential Tactile Narration)</em></div>

        <p><span class="section-label">Description:</span> In a circle or line, participants take turns touching a shared object or person and adding to an ongoing narrative, with touch cues marking the transitions. The haptic transfer of a "talking object" makes the tactile act itself part of the storytelling process (Hutchins 1995; Wegner 1987).</p>

        <p><span class="section-label">In practice:</span> Sit participants in a circle. Provide a single tactile object with multiple textures and affordances  (e.g., varied surfaces, edges, and attachments). The first person touches the object and begins a story or describes an experience. When finished, they pass the object (with touch) to the next person (the handover may include a gentle tap, pat, or specific haptic cue) and the next person continues the story or adds a related anecdote. Each speaker is encouraged to add a short physical gesture at the end of their turn (e.g. lightly squeezing the object). Continue around the circle until everyone has contributed, emphasising listening: each person should feel the object and the previous person's gesture as a cue. In some contexts touch is used specifically to manage next-speaker selection; this manuo-tactile turn-taking has been described in interactional studies of tactile signed and spoken interaction (Iwasaki et al. 2022; Blythe et al. 2024). The negotiated passing of touch also resonates with embodied pedagogy and dialogical practices of critique (Bresler 1996; Eisner 2002) and with theories of participatory sense-making in enactive cognition (Gallagher 2017; Hutto & Myin 2013).</p>

        <p>The session concludes with collective reflection: discuss how the chain of touch shaped the story and how the object's haptic history can be read back through touch. The "touch token" ensures even silent participants are physically involved and makes turn-taking explicit, building continuity as the communal story literally passes hand-to-hand. Such negotiated passing also speaks to traditions of bodily autonomy and consent cultures (Shakespeare 2006; Mackenzie 2022).</p>

        <p><span class="section-label">Relevance:</span> Tactile story chaining fosters active listening, inclusion and group cohesion. It trains narrative skills and empathy by making speaking presence physically legible; in arts education it can generate collective material for performance or exhibition. The tactile token can function as a distributed memory or transactive memory device for the group, the object carries cues and sequential history that participants can re-access (Hutchins 1995; Wegner 1987). Storytelling through material artefacts supports pedagogical access to narrative structures and imaginative framing (Egan 1988). It also models improvisational co-regulation and turn-taking practices rooted in socio-cultural theory (Vygotsky 1978; Sawyer 2003). For mixed-ability groups it is highly inclusive: blind participants access the same haptic turn cues and can lead or respond equally, and the tactile object becomes a shared mnemonic for later retelling. Trauma-informed protocols from SEL frameworks (SAMHSA 2014; CASEL 2020) further support its safe use in sensitive educational contexts.</p>

        <div class="references">
          Blythe, Hamdani & Barnes (2024) <a href="https://doi.org/10.1017/S0047404523000441">https://doi.org/10.1017/S0047404523000441</a><br>
          Bresler (1996) <a href="https://doi.org/10.1177/0022487196047004003">https://doi.org/10.1177/0022487196047004003</a><br>
          CASEL (2020) <a href="https://casel.org/wp-content/uploads/2020/12/CASEL-SEL-Framework-10.2020.pdf">https://casel.org/wp-content/uploads/2020/12/CASEL-SEL-Framework-10.2020.pdf</a><br>
          Egan (1988) <a href="https://press.uchicago.edu/ucp/books/book/chicago/T/bo3623439.html">https://press.uchicago.edu/ucp/books/book/chicago/T/bo3623439.html</a><br>
          Eisner (2002) <a href="https://doi.org/10.4324/9780203827926">https://doi.org/10.4324/9780203827926</a><br>
          Gallagher (2017) <a href="https://doi.org/10.4324/9781315747224">https://doi.org/10.4324/9781315747224</a><br>
          Hutchins (1995) <a href="https://mitpress.mit.edu/9780262581462/cognition-in-the-wild/">https://mitpress.mit.edu/9780262581462/cognition-in-the-wild/</a><br>
          Hutto & Myin (2013) <a href="https://doi.org/10.7551/mitpress/9780262018548.001.0001">https://doi.org/10.7551/mitpress/9780262018548.001.0001</a><br>
          Iwasaki et al. (2022) <a href="https://doi.org/10.1080/08351813.2022.2101293">https://doi.org/10.1080/08351813.2022.2101293</a><br>
          Mackenzie (2022) <a href="https://doi.org/10.1093/oso/9780192895568.001.0001">https://doi.org/10.1093/oso/9780192895568.001.0001</a><br>
          SAMHSA (2014) <a href="https://ncsacw.acf.hhs.gov/userfiles/files/SAMHSA_Trauma.pdf">https://ncsacw.acf.hhs.gov/userfiles/files/SAMHSA_Trauma.pdf</a><br>
          Sawyer (2003) <a href="https://doi.org/10.4324/9781410608888">https://doi.org/10.4324/9781410608888</a><br>
          Shakespeare (2006) <a href="https://doi.org/10.4324/9780203640082">https://doi.org/10.4324/9780203640082</a><br>
          Vygotsky (1978) <a href="https://doi.org/10.2307/1421414">https://doi.org/10.2307/1421414</a><br>
          Wegner (1987) <a href="https://doi.org/10.1007/978-1-4612-4634-3">https://doi.org/10.1007/978-1-4612-4634-3</a>
        </div>
      </div>

<!-- Strategy 7 -->
<div class="strategy" data-node="7">
  <div class="strategy-title">Touch-led Spatial Mapping <em>(Haptic Cartography)</em></div>

  <p><span class="section-label">Description:</span> Participants systematically explore and map a building's architectural features (walls, columns, textures, transitions) through sustained tactile contact, creating a haptic understanding of spatial structure. In mixed-ability groups, sighted and visually impaired participants work as co-researchers through paired exploration that equalizes and then exchanges expertise across phases. This approach draws on theories of embodied cognition in which spatial knowledge is grounded in sensorimotor experience (Varela, Thompson & Rosch 1991; Johnson 2007) and on research showing that active haptic exploration yields richer spatial representations than passive touch (Lederman & Klatzky 1987; Heller 1989). The pairing structure shifts from a helper model to collaborative discovery, operationalizing disability studies' social and cultural models that reframe blindness as sensory difference with distinct knowledges rather than deficit (Shakespeare 2006; Siebers 2008; Michalko 1998).</p>

  <p><span class="section-label">In practice:</span> Select a specific architectural space with varied surfaces: textured walls, door frames, columns, corners, different materials (brick, plaster, wood, metal). Pair participants intentionally: one sighted, one visually impaired per dyad where possible. Ensure the space is safe for independent movement: clear obstacles, announce thresholds. Brief all participants on respectful language: avoid "suffers from blindness" or "confined to visual impairment." Use identity-first ("blind person") or person-first ("person with visual impairment") per participant preference (NFB 2009). Establish consent protocols for physical contact at the outset, making clear that participation is voluntary and partners should verbally check in about comfort levels throughout (Mackenzie 2022; SAMHSA 2014).</p>

  <p><span class="section-label">Phase 1 (Mutual Exploration):</span> Both partners wear blindfolds or work in dimmed lighting. This levels the experiential field: sighted participants cannot rely on visual memory, forcing genuine haptic attention (Herssens & Heylighen 2009). Partners maintain light physical contact (one person's hand resting on the other's shoulder or both holding a shared tether) and verbally negotiate which surfaces to trace: "Let's follow this corner upward," "I'm feeling a transition here; rough to smooth."</p>

  <p>Guide participants to place both hands on a starting point (e.g., a wall corner) and instruct them to move slowly along surfaces, maintaining continuous contact. As they trace, they should attend to temperature changes, material transitions, seams, and edges. This methodical scanning mirrors the exploratory procedures identified in haptic perception research: lateral motion for texture, contour following for shape, and pressure for hardness (Lederman & Klatzky 1987).</p>

  <p>At corners or intersections, participants pause to trace joints with fingers: feeling angles, running hands up and down vertical edges to understand height and connection points. Partners vocalize discoveries in real-time: "The wall curves here," "There's a metal plate at knee height," "This threshold is raised about two fingers." A facilitator or additional partner can document these observations or use audio recording. Each dyad builds a continuous mental map, integrating new surfaces into their growing spatial schema (Thinus-Blanc & Gaunet 1997; Millar 1994).</p>

  <p>The visually impaired partner often becomes the natural leader in this phase, contributing greater tactile literacy and spatial reasoning skills developed through daily navigation practice (Thinus-Blanc & Gaunet 1997). Sighted partners learn to trust haptic information without visual confirmation; a key phenomenological shift that challenges vision-centrism (Paterson 2007). This negotiated navigation resonates with theories of participatory sense-making in enactive cognition, where meaning emerges through coordinated activity (Gallagher 2017; De Jaegher & Di Paolo 2007).</p>

  <p><span class="section-label">Phase 2 (Asymmetrical Expertise Exchange):</span> Remove blindfolds from sighted partners. Now sighted partners can see, but the task remains touch-focused: trace additional architectural features (door frames, heating vents, light switches, texture changes at different heights) and verbally describe them to the visually impaired partner in precise, non-visual language. This trains sighted participants in audio description skills (Snyder 2014) and challenges them to translate visual observation into actionable spatial information: "The doorframe is about three hand-widths from the corner, made of painted wood with a slight raised lip you can feel at the edge."</p>

  <p>Visually impaired partners provide feedback on description clarity and may identify haptic details the sighted partner missed visually: temperature differentials, air currents from ventilation, acoustic reflections, or subtle material compliance. Research shows blind individuals often detect surface properties (particularly texture and compliance) more accurately than sighted peers in timed tasks (Alary et al. 2009).</p>

  <p>Invite visually impaired participants to share orientation techniques they use daily (trailing walls, using cardinal directions, creating landmark chains, noting acoustic properties of spaces). Treat this explicitly as peer teaching, not demonstration, centering their expertise. This exchange models embodied pedagogy and dialogical practices of critique (Bresler 1996; Eisner 2002) and reflects critical pedagogy's emphasis on mutual transformation; both partners are changed by the encounter (Freire 1970).</p>

  <p><span class="section-label">Phase 3 (Collaborative Mapping):</span> Together, create a tactile map of the explored space using clay, textured papers, pipe cleaners, raised-line drawing tools, or fabric and found materials. The visually impaired partner's spatial schema (built from years of haptic navigation) informs overall layout and spatial relationships; the sighted partner contributes details observed visually. Negotiate discrepancies through re-exploration: "I felt three steps here," "I saw four. Let's trace them together again and count by touch."</p>

  <p>This collaborative construction models Universal Design principles (Story, Mueller & Mace 1998) and distributed cognition. The pair functions as a single cognitive system with complementary sensory inputs (Hutchins 1995). The resulting artifact serves as a shared mnemonic, a transactive memory device for the group that carries the sequential history of exploration (Wegner 1987). The tactile map becomes a tangible archive of the collaborative encounter, preserving otherwise ephemeral haptic discoveries.</p>

  <p>After creating maps, dyads present their representations to the full group. Compare maps, noting which architectural features were salient haptically versus visually, which were missed by different sensory approaches, and how bodies calibrated scale through arm extension and stride (Proffitt 2006). Discussion can address how different materials "announce" themselves through temperature, texture, or acoustic reflection, and how affordances (what surfaces offer for action) differ across sensory modes (Gibson 1979).</p>

  <p>Facilitate explicit discussion of power dynamics: How did roles shift across phases? When did each partner feel expert or novice? What assumptions about ability and spatial competence surfaced during the exercise? This surfaces and challenges ableist assumptions embedded in design education and spatial practices (Garland-Thomson 2002; Titchkosky 2011). The session models improvisational co-regulation and turn-taking practices rooted in socio-cultural theory (Vygotsky 1978; Sawyer 2003).</p>

  <p>This method extends research on blind mobility and orientation (Hill & Ponder 1976; Long & Giudice 2010) into collaborative pedagogy. It connects to phenomenological accounts of architectural experience as fundamentally kinaesthetic (Pallasmaa 2005; Bloomer & Moore 1977) and to ecological psychology's emphasis on environment-body couplings rather than abstract representations (Gibson 1979).</p>

  <p><span class="section-label">Relevance:</span> This strategy builds authentic inclusion beyond tokenism, teaching building literacy through embodied knowledge while challenging ableist assumptions. It is essential for orientation and mobility training, architectural accessibility design, and spatial cognition research. For blind and low-vision participants, it formalizes everyday navigation practices into explicit pedagogy and offers rare opportunity to be recognized as spatial experts rather than accommodated users (Long & Giudice 2010).</p>

  <p>For sighted participants, blindfolded tracing provides visceral understanding of how non-visual users experience built environments; a foundation for Universal Design thinking (Hamraie 2017; Herssens & Heylighen 2009). Many report profound destabilization of vision-centrism and new appreciation for non-visual ways of knowing (Paterson 2007). The method also supports multisensory learning theories showing that kinaesthetic engagement deepens spatial memory (Morrongiello et al. 1995).</p>

  <p>In architecture and design education, this exercise develops concrete accessibility competencies (verbal description, tactile communication, non-visual spatial reasoning) while demonstrating how environmental barriers are socially constructed rather than inevitable. Students gain embodied understanding that vision-centric design excludes entire modes of spatial experience. In community settings, collaborative architectural tracing generates collective spatial narratives and challenges ocular-centric assumptions about how we "know" place (Paterson 2007; Rodaway 1994).</p>

  <p>The paired structure reflects critical pedagogy's emphasis on reciprocal learning. Both partners contribute distinct knowledges and both are transformed (Freire 1970). By treating disability as valued identity and alternate embodiment rather than impairment, it operationalizes cultural models of disability in tangible practice (Shakespeare 2006; Siebers 2008). The method is highly inclusive for mixed-ability groups: participants access the same haptic information and contribute equally to map-making, with sensory difference positioned as epistemic resource rather than limitation.</p>

  <div class="references">
  Alary et al. (2009) <a href="https://doi.org/10.1007/s00221-008-1355-6">https://doi.org/10.1007/s00221-008-1355-6</a><br>
  Bloomer & Moore (1977) <a href="https://yalebooks.yale.edu/book/9780300021424/body-memory-and-architecture/">https://yalebooks.yale.edu/book/9780300021424/body-memory-and-architecture/</a><br>
  Bresler (1996) Journal of Curriculum and Supervision 11(2), 114–135<br>
  De Jaegher & Di Paolo (2007) <a href="https://doi.org/10.1007/s11097-007-9076-9">https://doi.org/10.1007/s11097-007-9076-9</a><br>
  Eisner (2002) <a href="https://doi.org/10.4324/9780203827926">https://doi.org/10.4324/9780203827926</a><br>
  Freire (1970) <a href="https://www.taylorfrancis.com/chapters/edit/10.4324/9780429339530-34/pedagogy-oppressed-paulo-freire">https://www.taylorfrancis.com/chapters/edit/10.4324/9780429339530-34/pedagogy-oppressed-paulo-freire</a><br>
  Gallagher (2017) <a href="https://doi.org/10.4324/9781315747224">https://doi.org/10.4324/9781315747224</a><br>
  Garland-Thomson (2002) NWSA Journal 14(3), 1–32<br>
  Gibson (1979) <a href="https://mitpress.mit.edu/9780262521239/the-ecological-approach-to-visual-perception/">https://mitpress.mit.edu/9780262521239/the-ecological-approach-to-visual-perception/</a><br>
  Hamraie (2017) <a href="https://www.upress.umn.edu/book-division/books/building-access">https://www.upress.umn.edu/book-division/books/building-access</a><br>
  Heller (1989) <a href="https://doi.org/10.1068/p180379">https://doi.org/10.1068/p180379</a><br>
  Herssens & Heylighen (2009) Proceedings of the IASDR Conference<br>
  Hill & Ponder (1976) <a href="https://www.afb.org/">https://www.afb.org/</a><br>
  Hutchins (1995) <a href="https://mitpress.mit.edu/9780262581462/cognition-in-the-wild/">https://mitpress.mit.edu/9780262581462/cognition-in-the-wild/</a><br>
  Johnson (2007) <a href="https://press.uchicago.edu/ucp/books/book/chicago/M/bo5417890.html">https://press.uchicago.edu/ucp/books/book/chicago/M/bo5417890.html</a><br>
  Lederman & Klatzky (1987) <a href="https://doi.org/10.1016/0010-0285(87)90008-9">https://doi.org/10.1016/0010-0285(87)90008-9</a><br>
  Long & Giudice (2010) <a href="https://www.afb.org/aw/22/6/15332">https://www.afb.org/aw/22/6/15332</a><br>
  Mackenzie (2022) <a href="https://doi.org/10.1093/oso/9780192895568.001.0001">https://doi.org/10.1093/oso/9780192895568.001.0001</a><br>
  Michalko (1998) <a href="https://utorontopress.com/9780802041951/the-mystery-of-the-eye-and-the-shadow-of-blindness">https://utorontopress.com/9780802041951/the-mystery-of-the-eye-and-the-shadow-of-blindness</a><br>
  Millar (1994) <a href="https://global.oup.com/academic/product/understanding-and-representing-space-9780198521426">https://global.oup.com/academic/product/understanding-and-representing-space-9780198521426</a><br>
  Morrongiello et al. (1995) Journal of Experimental Child Psychology 59(2), 211–233<br>
  National Federation of the Blind (2009) <a href="https://nfb.org/">https://nfb.org/</a><br>
  Pallasmaa (2005) <a href="https://www.wiley.com/en-us/The+Eyes+of+the+Skin%3A+Architecture+and+the+Senses%2C+3rd+Edition-p-9781119941286">https://www.wiley.com/en-us/The+Eyes+of+the+Skin%3A+Architecture+and+the+Senses%2C+3rd+Edition-p-9781119941286</a><br>
  Paterson (2007) <a href="https://www.bloomsbury.com/us/the-senses-of-touch-9781847882707/">https://www.bloomsbury.com/us/the-senses-of-touch-9781847882707/</a><br>
  Proffitt (2006) <a href="https://doi.org/10.1111/j.1745-6916.2006.00008.x">https://doi.org/10.1111/j.1745-6916.2006.00008.x</a><br>
  Rodaway (1994) <a href="https://www.routledge.com/Sensuous-Geographies-Body-Sense-and-Place/Rodaway/p/book/9780415098908">https://www.routledge.com/Sensuous-Geographies-Body-Sense-and-Place/Rodaway/p/book/9780415098908</a><br>
  SAMHSA (2014) <a href="https://ncsacw.acf.hhs.gov/userfiles/files/SAMHSA_Trauma.pdf">https://ncsacw.acf.hhs.gov/userfiles/files/SAMHSA_Trauma.pdf</a><br>
  Sawyer (2003) <a href="https://doi.org/10.4324/9781410608888">https://doi.org/10.4324/9781410608888</a><br>
  Shakespeare (2006) <a href="https://doi.org/10.4324/9780203640082">https://doi.org/10.4324/9780203640082</a><br>
  Siebers (2008) <a href="https://www.press.umich.edu/206190/disability_theory">https://www.press.umich.edu/206190/disability_theory</a><br>
  Snyder (2014) <a href="https://acb.org/adp/vocaleyesguide.html">https://acb.org/adp/vocaleyesguide.html</a><br>
  Story, Mueller & Mace (1998) <a href="https://projects.ncsu.edu/ncsu/design/cud/pubs_p/pudfiletoc.htm">https://projects.ncsu.edu/ncsu/design/cud/pubs_p/pudfiletoc.htm</a><br>
  Thinus-Blanc & Gaunet (1997) Psychological Bulletin 121(1), 20–42<br>
  Titchkosky (2011) <a href="https://utorontopress.com/9780802095411/the-question-of-access/">https://utorontopress.com/9780802095411/the-question-of-access/</a><br>
  Varela, Thompson & Rosch (1991) <a href="https://mitpress.mit.edu/9780262720212/the-embodied-mind/">https://mitpress.mit.edu/9780262720212/the-embodied-mind/</a><br>
  Vygotsky (1978) <a href="https://doi.org/10.2307/1421414">https://doi.org/10.2307/1421414</a><br>
  Wegner (1987) <a href="https://doi.org/10.1007/978-1-4612-4634-3">https://doi.org/10.1007/978-1-4612-4634-3</a>
</div>
</div>
      <!-- Strategy 2 -->
      <div class="strategy" data-node="2">
        <div class="strategy-title">Object-As-Score Sculptural Tracing <em>(Material-Led Choreographic Notation)</em></div>

        <p><span class="section-label">Description:</span> Participants explore a single sculpture or object by hand and let its shape and texture "score" a movement or narrative response. The object's form inspires gestures or stories that emerge from tactile exploration.</p>

        <p><span class="section-label">In practice:</span> A distinct tactile object (such as a carved wooden sculpture, a 3D-printed form, or a patterned fabric board) is placed in front of the group and passed around. Each participant traces its edges, contours, and textures, and responds by shaping a spontaneous gesture or movement. For example, following a curved relief might lead to a swirling arm motion. One at a time, or in pairs, participants perform these movements, and afterward describe either verbally or gesturally what aspect of the object prompted their response. Objects and partners may be swapped to expand the repertoire, and blindfolds can be used to heighten tactile focus.</p>

        <p>The session concludes with collective reflection: participants may guess which object inspired a movement, or combine all gestures into a group choreography. This strategy strengthens tactile imagination, translates sensation into embodied expression, and emphasizes material presence as a dramaturgical source. It connects to enactivist accounts of situated sense-making (Di Paolo & De Jaegher 2007), material-led choreography in dance studies, and multisensory museum pedagogy (Candlin 2006).</p>

        <p><span class="section-label">Relevance:</span> Object-led tracing bridges tactile perception and expression, promoting creativity and empathy. In educational or museum contexts, this approach encourages deeper engagement: children invent dance moves from dinosaur fossils or textile patterns, linking science or history with art. It also models cross-modal thinking (touch→motion, texture→story). In participatory art, it transforms sculpture into a dynamic collaborator. Importantly, it can be fully inclusive: blind participants can create equivalent gestures, making it useful for mixed-ability groups.</p>

        <div class="references">
          Candlin (2006) <a href="https://doi.org/10.1177/1470412906066906">https://doi.org/10.1177/1470412906066906</a><br>
          De Jaegher & Di Paolo (2007) <a href="https://doi.org/10.1007/s11097-007-9076-9">https://doi.org/10.1007/s11097-007-9076-9</a>
        </div>
      </div>

      <!-- Strategy 3 -->
      <div class="strategy" data-node="3">
        <div class="strategy-title">Collaborative Tactile Weaving <em>(Material Mnemonics and Storymaking)</em></div>

        <p><span class="section-label">Description:</span> A group collectively weaves, knots, or interlaces materials (yarn, strips of cloth, branches) to encode shared stories or memories into the textile pattern. Each strand functions as a narrative token; the emerging fabric records sequential contributions and becomes a tactile archive of communal authorship (Malafouris 2013).</p>

        <p><span class="section-label">In practice:</span> Prepare long strips of fibre or yarn and a simple communal loom or frame; brief participants on a story, poem, or collective theme and assign each person a position at the loom or line. One by one, participants weave or tie a strand into the textile while verbally narrating a brief piece of the story or recalling a memory; for example, each person might weave a different-coloured strand while speaking one line of a poem. As the fabric grows, everyone touches and attends to the emerging pattern; facilitators encourage texture–meaning mapping (if someone says "I felt calm by the lake," they might select a smooth blue strand). The activity can be conducted with speech or as a tactile-only protocol in which agreed haptic cues (e.g. a pulled knot = "happy memory") encode meaning. Objects and partners may be swapped to expand the repertoire, and motor-access adaptations (larger loops, pre-cut strands) can be provided to enable full participation (Case-Smith 2014).</p>

        <p>The session concludes with collective reflection: the group discusses how the interlaced materials embody the shared narrative and how the physical pattern represents individual contributions; the finished textile serves as a mnemonic device and may be used subsequently as a score for movement, storytelling, or exhibition. This strategy embeds narrative in material form, supports sequential coordination and pattern recognition, and foregrounds craft as a site of co-authorship; it draws on craft and material-culture practices in which textiles carry communal memory and relational knowledge. The method also resonates with literature on making as social connection (Gauntlett 2011) and ritualized, emergent discourse (Turner 1969).</p>

        <p><span class="section-label">Relevance:</span> Collaborative Tactile Weaving links material practice with collective narration and embodied memory. In educational or community contexts it creates multimodal connections between curricular content (local history, ecology, or science) and sensory learning: children might encode a river's ecosystem as colours and textures, or map a timeline of events into woven sequence. The method fosters empathy by making others' contributions physically legible and supports mixed-ability participation because the woven object is itself an accessible archive that blind participants can feel and use to retrieve and retell embedded stories.</p>

        <div class="references">
          Case-Smith et al. (2013) <a href="https://doi.org/10.5014/ajot.2013.005959">https://doi.org/10.5014/ajot.2013.005959</a><br>
          Gauntlett (2011) <a href="https://www.politybooks.com/bookdetail/?isbn=9780745650023">https://www.politybooks.com/bookdetail/?isbn=9780745650023</a><br>
          Malafouris (2019) <a href="https://doi.org/10.1007/s11097-018-9606-7">https://doi.org/10.1007/s11097-018-9606-7</a><br>
          Turner (1969) <a href="https://doi.org/10.4324/9781315134666">https://doi.org/10.4324/9781315134666</a>
        </div>
      </div>

      <!-- Strategy 4 -->
      <div class="strategy" data-node="4">
        <div class="strategy-title">Anticipatory Tactility <em>(Imagined Haptic Encounters)</em></div>

        <p><span class="section-label">Description:</span> Participants are asked to form a prediction of an object's tactile qualities (e.g., smooth, bumpy, warm, sharp) before touching it, then to confirm or revise that mental haptic image through direct touch and reflective comparison. The method foregrounds pre-touch inference and reconditioning of sensory models via exploratory touch (Lederman & Klatzky 1987; O'Regan & Noë 2001; Barsalou 1999).</p>

        <p><span class="section-label">In practice:</span> Present a real object without allowing touch and invite participants to record a brief tactile ledger using non-visual, touchable means; examples include spoken keywords recorded by the facilitator, embossed or Braille notes, small tactile tokens (e.g., textured/various sized beads, textured chips) placed in labelled piles. Rely on non-visual cues (size by hand placement, scent, sound from handling, or a verbal prompt). If you intend the activity to be sight independent; these crossmodal cues also let instantiate expectations in predictable ways (Shams & Seitz 2008; Spence 2011). After the prediction phase, remove visual access (blindfold) and allow free or guided tactile exploration using standard exploratory procedures (pressure, lateral motion, enclosure, contour following) encouraging participants to note which procedures they use and why (Lederman & Klatzky 1987). Following the touch phase, prompt paired reflection (verbal report + tactile ledger update) to compare expectation and sensation: what matched, what surprised (temperature, compliance, microtexture), so participants explicitly attend to how material cues shaped their anticipatory model (Gibson 1979; Malafouris 2013). For variants that intensify tactile attention, run the exercise wholly without any visual presentation, using only verbal description or other non-visual cues and the tactile ledger; a mindfulness framing can help slow exploration and increase sensitivity to subtle differences. The approach thus trains metacognitive awareness of sensory inference while keeping the protocol operable in low or no vision contexts (Merleau-Ponty 1962; O'Regan & Noë 2001).</p>

        <p><span class="section-label">Relevance:</span> Anticipatory Tactility strengthens haptic discrimination, articulacy about touch, and the ability to revise sensory expectations; skills valuable in object-based arts education, accessibility training (orientation & mobility; guide work), and sensory awareness practices. By avoiding reliance on visual tools and by making prediction and feedback tactile and discussable, the method supports inclusion and creates teachable haptic strategies grounded in exploratory procedures, sensorimotor contingency theory, and material engagement (Lederman & Klatzky 1987; O'Regan & Noë 2001; Malafouris 2013). Making crossmodal cues explicit and then testing them through touch demonstrates how prior cues produce actionable expectations that are updated by exploratory touch (Shams & Seitz 2008; Spence 2011).</p>

        <div class="references">
          Barsalou (1999) <a href="https://doi.org/10.1017/S0140525X99002149">https://doi.org/10.1017/S0140525X99002149</a><br>
          Gibson (1979) <a href="https://doi.org/10.4324/9780203784175">https://doi.org/10.4324/9780203784175</a><br>
          Lederman & Klatzky (1987) <a href="https://doi.org/10.1037/0033-295X.94.2.211">https://doi.org/10.1037/0033-295X.94.2.211</a><br>
          Malafouris (2013) <a href="https://doi.org/10.7551/mitpress/9476.001.0001">https://doi.org/10.7551/mitpress/9476.001.0001</a><br>
          Merleau-Ponty (1962) <a href="https://doi.org/10.4324/9780203994611">https://doi.org/10.4324/9780203994611</a><br>
          O'Regan & Noë (2001) <a href="https://doi.org/10.1017/S0140525X01000115">https://doi.org/10.1017/S0140525X01000115</a><br>
          Shams & Seitz (2008) <a href="https://doi.org/10.1162/jocn.2008.20091">https://doi.org/10.1162/jocn.2008.20091</a><br>
          Spence (2011) <a href="https://doi.org/10.1016/j.tics.2011.06.005">https://doi.org/10.1016/j.tics.2011.06.005</a>
        </div>
      </div>

      <!-- Strategy 5 -->
      <div class="strategy" data-node="5">
        <div class="strategy-title">Guided Tactile Circuit <em>(Sequential Touch Improvisation)</em></div>

        <p><span class="section-label">Description:</span> Participants form a physical circuit of touch, passing improvised tactile signals around a circle or chain, creating collective rhythms, patterns, or narratives. Each touch is both a response and a cue, producing distributed composition and heightened haptic attunement (Ingold 2011; Bishop 2012).</p>

        <p><span class="section-label">In practice:</span> Arrange participants in a circle or line with physical contact (e.g., each person lightly holds their neighbour's wrist or shoulder). The facilitator initiates a simple haptic pulse (a tap, stroke, squeeze) and passes it along the line; each participant repeats or varies it before relaying it onward. Once the pulse returns, variations can be introduced: alternating rhythms, layered touches, or cross-circle signals. Blindfolds can equalise reliance on tactile cues. The facilitator may then invite participants to use haptic motifs to express feelings, events, or narrative fragments (e.g., a trembling hand as "storm," a gentle squeeze as "friendship").</p>

        <p>The session concludes with collective reflection: how did it feel to be part of the haptic circuit, how did signals change in transmission, and what emergent rhythms arose? The method can be expanded into performance scores (circuits as live improvisations) or therapeutic workshops (focusing on synchronisation, empathy, trust-building). It resonates with distributed creativity (Sawyer & DeZutter 2009), improvisational theatre, and anthropological accounts of skill transmission as rhythmic attunement (Ingold 2011).</p>

        <p><span class="section-label">Relevance:</span> Haptic Circuit cultivates attention to micro-variation in touch, enhances group coordination, and generates collective meaning without reliance on vision or speech. It is applicable in dance, theatre, music ensembles, and inclusive education. The method supports trauma-informed and consent-led facilitation: participants can always stop or alter the signal, affirming bodily autonomy while building co-regulation skills.</p>

        <div class="references">
          Bishop (2012) <a href="https://doi.org/10.4324/9780203805825">https://doi.org/10.4324/9780203805825</a><br>
          Ingold (2011) <a href="https://doi.org/10.4324/9780203841939">https://doi.org/10.4324/9780203841939</a><br>
          Sawyer & DeZutter (2009) <a href="https://doi.org/10.1017/S135132490999004X">https://doi.org/10.1017/S135132490999004X</a>
        </div>
      </div>
     <!-- Strategy 6 -->
 <div class="strategy" data-node="6">
        <div class="strategy-title">Mirrored Haptic Exploration <em>(Kinesthetic Pairing)</em></div>

        <p><span class="section-label">Description:</span> Two participants sit or stand facing the same shared object; one leads with tactile gestures while the other mirrors those gestures in real time on the same object, creating a coordinated haptic rhythm and force pattern (Chartrand & Bargh 1999; Dupin, Hayward & Wexler 2015).</p>

        <p><span class="section-label">In practice:</span> Pair participants and provide a single object with salient affordances (e.g., a block of clay, a soft ball, or a textured fabric). Partners position themselves across the object so both can touch it simultaneously. One person begins as the leader and explores the object by touch (squeezing, stroking, tracing edges, varying pressure or direction) for a short interval (30–90 s) while the other attempts to mirror those same motions on the object; matching tempo, pressure and trajectory without verbal instruction. After the interval partners swap roles; facilitators may introduce variations (blindfolded rounds to emphasise haptic cues, tempo/pressure shifts, or a three-way relay) and encourage minimal nonverbal coordination signals (breath, small taps) to support transitions. Prior to beginning, obtain explicit consent, explain opt-out signals, and offer alternatives for participants who prefer not to engage in direct touch.</p>

        <p>The session concludes with collective reflection: Invite pairs to report how well rhythm, trajectory and pressure were matched and what cues helped alignment. Discuss whether the object’s material amplified or dampened perceived gestures and what nonverbal strategies (timing, micro-cues) emerged. Reflect on comfort, boundaries, and whether the activity felt synchronising or challenging; surface anything that suggests adapting duration, object choice, or consent protocols for future rounds.</p>

        <p><span class="section-label">Relevance:</span> Mirrored haptic exercises harness basic social mirroring and sensorimotor coupling to build interpersonal attunement, coordination and shared affective regulation (Chartrand & Bargh 1999; Chatel-Goldman et al. 2014). In drama and movement training they function like sighted mirroring exercises but foreground touch and force; in education and mixed-ability classrooms they support inclusive embodied listening because tactile cues are accessible to people with visual impairments (Lederman & Klatzky 1993). From a clinical or co-regulation perspective, tactile synchrony can promote physiological coupling and grounding when used with trauma-aware safeguards (SAMHSA 2014). For designers and HCI researchers, the exercise offers a low-tech analogue of haptic shared control and force-feedback studies that examine how graded pressure and texture support collaborative fluency (Abbink et al. 2012; Dupin et al. 2015). Practitioners should always prioritise consent, provide non-touch alternatives, and include debriefing so the activity remains safe and facilitative.</p>

        <div class="references">
          Abbink, D., et al. (2012) <a href="https://doi.org/10.4324/9780203805825">https://doi.org/10.4324/9780203805825</a><br>
          Chartrand, T. L., & Bargh, J. A. (1999)<a href="https://doi.org/10.4324/9780203841939">https://doi.org/10.4324/9780203841939</a><br>
          Chatel-Goldman, J., et al. (2014) <a href="https://doi.org/10.1017/S135132490999004X">https://doi.org/10.1017/S135132490999004X</a><br>
          Dupin, L., Hayward, V., & Wexler, M. (2015) <a href="https://doi.org/10.1017/S135132490999004X">https://doi.org/10.1017/S135132490999004X</a><br>
          Lederman, S. J., & Klatzky, R. L. (1993) <a href="https://doi.org/10.1017/S135132490999004X">https://doi.org/10.1017/S135132490999004X</a><br>
          SAMHSA (2014) <a href="https://doi.org/10.1017/S135132490999004X">https://doi.org/10.1017/S135132490999004X</a>
        </div>
      </div>
    </div>
  </div>
  
<!-- Fixed right-side interactive network -->
<div id="bg-network-panel" role="complementary" aria-label="Interactive strategy network">
  <div id="bg-network" aria-hidden="false" tabindex="0"></div>
</div>

<!-- Horizontal legend directly below the panel -->
<div id="network-legend-box">
  <em>Social</em> &nbsp; Red &nbsp; &nbsp; <em>Material</em> &nbsp; Black &nbsp; &nbsp; <em>Sensory</em> &nbsp; Dark Red &nbsp; &nbsp; <em>Spatial</em> &nbsp; Beige

</div>

<style>
  /* Right-side panel */
  #bg-network-panel {
    position: fixed;
    bottom: 20px;
    right: 10px;
    width: 660px;
    height: 460px;
    max-width: 90vw;
    max-height: 50vh;
    background: transparent;
    border-radius: 10px;
    z-index: 9999;
    padding: 12px;
    font-family: 'Arial', sans-serif;
    display: flex;
    flex-direction: column;
    border: none;
    box-shadow: none;
  }

  #bg-network {
    flex: 1 1 auto;
    width: 100%;
    height: 100%;
    background: transparent;
    border-radius: 6px;
    position: relative;
  }

  /* Legend box under the network panel */
  #network-legend-box {
    position: fixed;
    bottom: 0;
    right: 10px;
    width: 660px;
    max-width: 90vw;
    text-align: center;
    font-family: 'Garamond', serif;
    font-size: 12px;
    font-weight: normal;
    color: #000;
    z-index: 10002;
    margin-bottom: 13px;
  }
</style>

<script src="https://unpkg.com/vis-network/standalone/umd/vis-network.min.js"></script>

<script>
(function() {
 const strategyMap = { 1:0, 2:1, 3:2, 4:3, 5:4, 6:5, 7:6 };

  const nodes = new vis.DataSet([
    { id: 1, label: "Tactile Storying", group: "social", title: "Sequential tactile narration." },
    { id: 2, label: "Object-As-Score", group: "material", title: "Material-led tracing" },
    { id: 3, label: "Collaborative Weaving", group: "material", title: "Collective weaving" },
    { id: 4, label: "Anticipatory Tactility", group: "sensory", title: "Predict → touch → reflect" },
    { id: 5, label: "Guided Tactile Circuit", group: "social", title: "Sequential touch improvisation" },
    { id: 6, label: "Mirrored Haptic Exploration", group: "social", title: "Kinesthetic Pairing" },
    { id: 7, label: "Touch-led Spatial Exploration", group: "spatial", title: "Haptic Cartography" }

  ]);

   const edges = new vis.DataSet([
    { from: 1, to: 3 },
    { from: 1, to: 5 },
    { from: 2, to: 4 },
    { from: 3, to: 5 },
    { from: 4, to: 7 },
    { from: 2, to: 6 },
    { from: 6, to: 7 },
    { from: 4, to: 5 },  // NEW bridge: sensory ↔ social
    { from: 7, to: 3 }   // NEW bridge: spatial ↔ material
  ]);

  function initNetwork() {
    const container = document.getElementById('bg-network');
    if (!container) return;

    const data = { nodes, edges };

    const options = {
      nodes: {
        shape: 'dot',
        size: 13,
        font: { size: 13, color: '#000000', face: 'Arial, sans-serif', vadjust: 0, align: 'center' },
        color: {
          border: '#000',
          highlight: { background: '#d10000', border: '#d10000' },
          hover: { background: '#d10000', border: '#d10000' }
        },
        borderWidth: 1.6,
        margin: 4
      },
      edges: {
        color: { color: '#bbb' },
        width: 1.6,
        smooth: { enabled: true, type: 'cubicBezier' },
        dashes: [5, 5]
      },
      groups: {
        social:  { color: { background: '#d10000', border: '#b30000' }, font: { color: '#000000' } },
        material:{ color: { background: '#000000', border: '#000000' }, font: { color: '#000000' } },
        sensory: { color: { background: '#800000', border: '#5a0000' }, font: { color: '#000000' } },
        spatial: { color: { background: '#ffcccc', border: '#ffbebe' }, font: { color: '#000000' } }
      },
      interaction: {
        hover: true,
        tooltipDelay: 100,
        dragView: true,
        dragNodes: true,
        multiselect: true,
        zoomView: false
      },
      physics: {
        stabilization: true,
        barnesHut: { gravitationalConstant: -3000, springLength: 140, springConstant: 0.02 }
      },
      layout: { improvedLayout: true }
    };

    const network = new vis.Network(container, data, options);

    function resizeNetwork() {
      const panel = document.getElementById('bg-network-panel');
      if(!panel) return;
      const w = Math.min(560, window.innerWidth - 20);
      const h = Math.min(460, window.innerHeight - 20);
      panel.style.width = (window.innerWidth < 560 ? w : 560) + 'px';
      panel.style.height = (window.innerHeight < 460 ? h : 460) + 'px';
      container.style.width = '100%';
      container.style.height = '100%';
      network.redraw();
    }
    window.addEventListener('resize', resizeNetwork);

    // Click -> scroll to strategy
    network.on('click', function(params) {
      if (!params.nodes || !params.nodes.length) return;
      const nodeId = params.nodes[0];
      const idx = strategyMap[nodeId];
      const strategies = document.querySelectorAll('.strategy');
      const target = strategies[idx];
      if (target) {
        window.scrollTo({ top: target.offsetTop - 20, behavior: 'smooth' });
        network.selectNodes([nodeId]);
        nodes.update({ id: nodeId, size: 28 });
        setTimeout(() => nodes.update({ id: nodeId, size: 20 }), 650);
      }
    });

    // Highlight node based on scroll
    const strategies = Array.from(document.querySelectorAll('.strategy'));
    const observedMap = {};
    for (const [nodeId, idx] of Object.entries(strategyMap)) {
      if (strategies[idx]) observedMap[idx] = Number(nodeId);
    }

    const io = new IntersectionObserver(entries => {
      let best = null;
      entries.forEach(ent => { if (!best || ent.intersectionRatio > best.intersectionRatio) best = ent; });
      if (best && best.intersectionRatio > 0.3) {
        const index = strategies.indexOf(best.target);
        const nodeId = observedMap[index];
        if (nodeId) {
          network.selectNodes([nodeId]);
          nodes.update({ id: nodeId, size: 26 });
          Object.values(observedMap).forEach(id => { if (id !== nodeId) nodes.update({ id: id, size: 20 }); });
        }
      }
    }, { root: null, rootMargin: '0px', threshold: [0.3, 0.6] });
    strategies.forEach(s => io.observe(s));

    // Accessibility live region
    const live = document.createElement('div');
    live.setAttribute('aria-live', 'polite');
    live.style.position = 'absolute';
    live.style.left = '-9999px';
    live.style.width = '1px';
    live.style.height = '1px';
    document.body.appendChild(live);

    network.on('selectNode', function(params) {
      if (!params.nodes || !params.nodes.length) return;
      const id = params.nodes[0];
      const idx = strategyMap[id];
      const label = strategies[idx]?.querySelector('.strategy-title')?.innerText || nodes.get(id).label;
      live.textContent = label + ' selected';
    });
  }

  if (document.getElementById('bg-network')) initNetwork();
  else setTimeout(() => { if (document.getElementById('bg-network')) initNetwork(); }, 80);
})();
</script>
  <script>
  const synth = window.speechSynthesis;

  function readPage() {
    synth.cancel();
    const text = document.querySelector('.main-content').innerText;
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = "en-US";
    utterance.rate = 1;
    utterance.pitch = 1;
    synth.speak(utterance);
  }

  function stopReading() {
    synth.cancel();
  }

  document.getElementById("readTextBtn").addEventListener("click", readPage);
  document.getElementById("stopTextBtn").addEventListener("click", stopReading);
</script>
<script>
document.addEventListener("DOMContentLoaded", function() {
  // Toggle the Practice menu
 document.querySelectorAll('.main-glide-btn').forEach(button => {
  button.addEventListener('click', (e) => {
    e.preventDefault();
    const glideMenu = button.closest('.glide-menu');
    if (glideMenu) glideMenu.classList.toggle('active');
  });
});

  // Text-to-speech buttons
  const readBtn = document.getElementById('readTextBtn');
  const stopBtn = document.getElementById('stopTextBtn');
  const synth = window.speechSynthesis;

  readBtn.addEventListener('click', () => {
    const text = document.querySelector('.main-content').innerText;
    if (synth.speaking) synth.cancel();
    const utter = new SpeechSynthesisUtterance(text);
    synth.speak(utter);
  });

  stopBtn.addEventListener('click', () => {
    if (synth.speaking) synth.cancel();
  });
});
</script>
</body>
</html>
